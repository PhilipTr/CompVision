{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352481e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3e333-8539-4fc1-967d-49a767c0350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae9e2cc-7672-481c-a83e-d1dc3d0d05da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your own dataset path\n",
    "train_img_dir = \"ferplus/FER2013Plus/Images/FER2013Train\"\n",
    "val_img_dir   = \"ferplus/FER2013Plus/Images/FER2013Valid\"\n",
    "train_lbl_csv = \"ferplus/FER2013Plus/Labels/FER2013Train/label.csv\"\n",
    "val_lbl_csv   = \"ferplus/FER2013Plus/Labels/FER2013Valid/label.csv\"\n",
    "\n",
    "class FERPlusSoftDataset(Dataset):\n",
    "    def __init__(self, images_dir, label_csv_path, transform=None, confidence_threshold=0.4):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(images_dir))\n",
    "\n",
    "        df = pd.read_csv(label_csv_path, header=None)\n",
    "        self.labels = df.iloc[:, 2:10].values.astype(np.float32)\n",
    "\n",
    "\n",
    "        # Normalize votes to sum to 1 (turn votes into probability distribution)\n",
    "        self.labels = self.labels / np.clip(self.labels.sum(axis=1, keepdims=True), 1e-6, None)\n",
    "\n",
    "        # Filter samples based on vote confidence\n",
    "        confident_indices = []\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            if label.max() >= confidence_threshold:\n",
    "                confident_indices.append(idx)\n",
    "\n",
    "        self.image_files = [self.image_files[idx] for idx in confident_indices]\n",
    "        self.labels = self.labels[confident_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_filename)\n",
    "\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label_soft = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "        return img, label_soft\n",
    "\n",
    "class SoftLabelLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        log_preds = F.log_softmax(logits, dim=1)\n",
    "        loss = F.kl_div(log_preds, targets, reduction='batchmean')\n",
    "        return loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device):\n",
    "    model.eval(); correct = total = 0\n",
    "    for x, y_soft in loader:\n",
    "        x = x.to(device)\n",
    "        y_true = y_soft.argmax(dim=1).to(device)\n",
    "        pred = model(x).argmax(1)\n",
    "        correct += (pred == y_true).sum().item(); total += y_true.size(0)\n",
    "    return correct / total\n",
    "\n",
    "epochs      = 50\n",
    "batch_size  = 256\n",
    "lr          = 3e-4\n",
    "random_seed = 42\n",
    "use_gpu_id  = 0\n",
    "\n",
    "torch.manual_seed(random_seed); np.random.seed(random_seed); random.seed(random_seed)\n",
    "device = torch.device(f\"cuda:{use_gpu_id}\" if (torch.cuda.is_available() and use_gpu_id >= 0) else \"cpu\")\n",
    "print(\"Using\", device)\n",
    "\n",
    "train_tfm = T.Compose([\n",
    "    T.Grayscale(1),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandAugment(num_ops=2, magnitude=5),\n",
    "    T.RandomRotation(10, interpolation=InterpolationMode.BILINEAR),\n",
    "    T.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    T.ColorJitter(0.1, 0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "val_tfm = T.Compose([\n",
    "    T.Grayscale(1),\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_ds = FERPlusSoftDataset(train_img_dir, train_lbl_csv, transform=train_tfm)\n",
    "val_ds   = FERPlusSoftDataset(val_img_dir, val_lbl_csv, transform=val_tfm)\n",
    "\n",
    "subset_percent = 1.0 \n",
    "if subset_percent < 1.0:\n",
    "    subset_size = int(len(train_ds) * subset_percent)\n",
    "    indices = np.random.choice(len(train_ds), subset_size, replace=False)\n",
    "    train_ds = Subset(train_ds, indices)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "n_classes = 8\n",
    "\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "if model_name.startswith(\"resnet\"):\n",
    "    model = getattr(models, model_name)(weights=\"DEFAULT\")\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, 2, 3, bias=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 8)  # Force output to 8\n",
    "else:\n",
    "    model = models.efficientnet_b2(weights=\"DEFAULT\")\n",
    "    model.features[0][0] = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
    "    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 8)  # Force output to 8\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = SoftLabelLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs * len(train_loader))\n",
    "scaler    = torch.cuda.amp.GradScaler(enabled=device.type == \"cuda\")\n",
    "\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "best = 0.0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\")\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=device.type == \"cuda\"):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    train_loss_epoch = running_loss / len(train_loader.dataset)\n",
    "    train_losses.append(train_loss_epoch)\n",
    "\n",
    "    acc = evaluate(model, val_loader, device)\n",
    "    val_accuracies.append(acc)\n",
    "\n",
    "    print(f\"Val acc: {acc:.4f}\")\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        torch.save(model.state_dict(), \"best.pth\")\n",
    "        print(\"â†’ saved best.pth\")\n",
    "\n",
    "print(f\"Training complete. Best validation accuracy = {best:.4f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Progress\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d5b9a-172b-4a1c-8093-492cee44ea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(val_accuracies, label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
